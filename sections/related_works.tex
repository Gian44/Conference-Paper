\section{Related Work}

We first consider the application of Ant Colony Optimization (ACO) to Sudoku. ACO is a population-based search method inspired by the foraging behaviour of ants \cite{dorigo1992}, and it has been successfully applied to a wide range of computational problems. The basic ACO algorithm uses a population of agents, or ``ants'', which individually explore a given problem space and incrementally construct a solution, guided by a global pheromone data structure that is used to inform the decisions taken by the ants. Components associated with higher pheromone concentrations are more likely to be selected, creating a positive feedback loop that steers the population towards high-quality solutions. Premature convergence is discouraged through continuous evaporation of pheromone concentrations. Since the publication of the original Ant System \cite{dorigo1992}, several variants have been proposed, including Ant Colony System (ACS) and Max--Min Ant System (MMAS), each differing in how pheromone is deposited, evaporated, and bounded \cite{dorigo2004ant}.

Lloyd and Amos \cite{lloyd2020} present an algorithm for Sudoku based on ACS, combining constraint propagation (CP) \cite{norvig2006solving} with ACO-based search. Their CP component prunes the set of possible values for each cell whenever a value is fixed, effectively eliminating large portions of the search space in parallel. The ACO component then explores the remaining possibilities using pheromone-guided value selection: each ant works on its own copy of the board, iterating over cells and probabilistically choosing values according to pheromone concentrations stored in a global matrix. A local pheromone update discourages following ants from making the same choices, while a global update rewards the best-performing ant in each iteration. A key contribution of their work is the introduction of Best Value Evaporation (BVE), a novel anti-stagnation operator that subjects the globally deposited pheromone amount itself to evaporation over time, thereby preventing the algorithm from locking in to suboptimal solutions. Their method does not rely on any problem-specific heuristic information, which makes it potentially applicable to other constraint satisfaction problems beyond Sudoku.

While the single-colony approach of Lloyd and Amos \cite{lloyd2020} demonstrates the viability of ACO for Sudoku, single-colony methods inherently face a trade-off between convergence speed and solution diversity---improvements that accelerate convergence tend to reduce the exploration of the search space, and vice versa. To address this limitation in the context of the Travelling Salesman Problem, Mo et al. \cite{mo2022} propose a multi-colony ant optimization with dynamic collaborative mechanism and cooperative game (DCM-ACO). Their framework organises two ACS sub-colonies and one MMAS sub-colony into a heterogeneous population, leveraging the fast convergence of ACS alongside the diversity-preserving pheromone bounds of MMAS. To coordinate pheromone accumulation among the ACS sub-colonies, they introduce a cooperative game strategy based on the Shapley value, which redistributes the total pheromone income to each sub-colony in proportion to its contribution---measured as a function of both solution quality and population diversity (quantified via information entropy). In addition, they design a dynamic collaborative mechanism comprising two methods: a pheromone fusion mechanism that resets the pheromone distribution of a stagnating ACS colony by blending it with the MMAS colony's pheromone matrix, and a public path recommendation strategy that transfers commonly selected edges from the ACS colonies to the MMAS colony to accelerate its convergence. Although DCM-ACO was developed for the TSP rather than Sudoku, its multi-colony architecture and inter-colony communication strategies are directly relevant to this work, as they offer a principled way to balance exploration and exploitation across heterogeneous ant populations.

Separately, Yang et al. \cite{yang2015} address ACO scalability from the perspective of parallelism with a Randomly Matched Parallel Ant Colony Optimization (RMACO) algorithm implemented using MPI. RMACO distributes the search across multiple processors, each hosting its own sub-ant colony. A key design decision is the communication topology: each processor exchanges its iteration-best solution with its neighbour along a fixed ring topology, while simultaneously exchanging its best-so-far solution with a randomly matched processor that changes every exchange cycle. This dual-topology approach avoids the rapid assimilation that occurs under fully-connected topologies, while still enabling sufficient information sharing to guide convergence. RMACO further employs a non-fixed exchange cycle: longer intervals in the early iterations allow sub-colonies to explore their respective solution spaces independently, while shorter intervals in later iterations promote active exchange to accelerate convergence. The pheromone update after each exchange cycle incorporates contributions from three sources---the processor's own iteration-best, the ring neighbour's iteration-best, and the randomly matched processor's best-so-far---enabling ants to benefit from a broader set of search experiences. The ring-and-random communication strategy of RMACO is particularly relevant to our work, as it provides the foundation for the inter-thread communication topology adopted in SudoSLVRR.

Building on these three lines of work, our proposed framework, \textbf{SudoSLVRR}, integrates the constraint propagation and ACO-based search of Lloyd and Amos \cite{lloyd2020}, the heterogeneous multi-colony architecture and dynamic collaborative mechanism of Mo et al. \cite{mo2022}, and the ring-and-random parallel communication topology of Yang et al. \cite{yang2015}, within a multithreaded environment tailored for solving Sudoku puzzles of varying sizes.